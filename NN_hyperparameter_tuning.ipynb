{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "37z_A6moF2YN"
   },
   "outputs": [],
   "source": [
    "# Importing the necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 10.9 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: keras\n",
      "Successfully installed keras-2.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.6.0-cp38-cp38-manylinux2010_x86_64.whl (458.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 458.4 MB 10 kB/s s eta 0:00:01     |███████████████████             | 273.7 MB 10.6 MB/s eta 0:00:18     |█████████████████████████▏      | 360.5 MB 10.7 MB/s eta 0:00:10     |██████████████████████████▏     | 374.8 MB 12.4 MB/s eta 0:00:07\n",
      "\u001b[?25hCollecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 491 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/sachin/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 648 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp38-cp38-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 11.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/sachin/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.35.1)\n",
      "Collecting grpcio<2.0,>=1.37.0\n",
      "  Downloading grpcio-1.40.0-cp38-cp38-manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 12.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting tensorflow-estimator~=2.6\n",
      "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 12.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /home/sachin/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /home/sachin/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.19.2)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.18.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 12.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: keras~=2.6 in /home/sachin/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.6.0)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.14.0-py3-none-any.whl (131 kB)\n",
      "\u001b[K     |████████████████████████████████| 131 kB 14.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 15.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/sachin/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 11.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /home/sachin/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (50.3.1.post20201107)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 15.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "\u001b[K     |████████████████████████████████| 152 kB 12.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 1.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /home/sachin/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.24.0)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 11.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/sachin/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/sachin/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/sachin/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sachin/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.6.20)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "\u001b[K     |████████████████████████████████| 146 kB 12.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 700 kB/s  eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: termcolor, clang, wrapt\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=29e1dd1f55f576a55159dce0199b472c52794a82491e2a98ec9ebdacfefcbd3e\n",
      "  Stored in directory: /home/sachin/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "  Building wheel for clang (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30705 sha256=70c1da226cb4707581982f833dfbbfa4707563f96971b36033e67a09d63ca927\n",
      "  Stored in directory: /home/sachin/.cache/pip/wheels/f1/60/77/22b9b5887bd47801796a856f47650d9789c74dc3161a26d608\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp38-cp38-linux_x86_64.whl size=71601 sha256=cdd10ff12cfb0eb86f466b597878afda32cbf0a4f9c1c34effa947c967ca8802\n",
      "  Stored in directory: /home/sachin/.cache/pip/wheels/5f/fd/9e/b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
      "Successfully built termcolor clang wrapt\n",
      "Installing collected packages: google-pasta, termcolor, opt-einsum, h5py, clang, grpcio, wrapt, keras-preprocessing, tensorflow-estimator, protobuf, gast, absl-py, oauthlib, requests-oauthlib, cachetools, pyasn1, pyasn1-modules, rsa, google-auth, google-auth-oauthlib, tensorboard-data-server, tensorboard-plugin-wit, markdown, tensorboard, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.11.2\n",
      "    Uninstalling wrapt-1.11.2:\n",
      "      Successfully uninstalled wrapt-1.11.2\n",
      "Successfully installed absl-py-0.14.0 astunparse-1.6.3 cachetools-4.2.2 clang-5.0 flatbuffers-1.12 gast-0.4.0 google-auth-1.35.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.40.0 h5py-3.1.0 keras-preprocessing-1.1.2 markdown-3.3.4 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.18.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7.2 tensorboard-2.6.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.6.0 tensorflow-estimator-2.6.0 termcolor-1.1.0 wrapt-1.12.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0hLfVUZjF2YN"
   },
   "outputs": [],
   "source": [
    "# load pima indians dataset\n",
    "dataset = np.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Gyflyd1DF2YN"
   },
   "outputs": [],
   "source": [
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "k6oZWHwMF2YN"
   },
   "outputs": [],
   "source": [
    "# Standardization\n",
    "a = StandardScaler()\n",
    "a.fit(X)\n",
    "X_standardized = a.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "w6Blt2-IF2YN"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.680000e+02</td>\n",
       "      <td>7.680000e+02</td>\n",
       "      <td>7.680000e+02</td>\n",
       "      <td>7.680000e+02</td>\n",
       "      <td>7.680000e+02</td>\n",
       "      <td>7.680000e+02</td>\n",
       "      <td>7.680000e+02</td>\n",
       "      <td>7.680000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-7.748432e-17</td>\n",
       "      <td>3.614007e-18</td>\n",
       "      <td>-1.327244e-17</td>\n",
       "      <td>7.762888e-17</td>\n",
       "      <td>-5.493291e-17</td>\n",
       "      <td>2.972738e-15</td>\n",
       "      <td>1.924387e-15</td>\n",
       "      <td>2.192980e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000652e+00</td>\n",
       "      <td>1.000652e+00</td>\n",
       "      <td>1.000652e+00</td>\n",
       "      <td>1.000652e+00</td>\n",
       "      <td>1.000652e+00</td>\n",
       "      <td>1.000652e+00</td>\n",
       "      <td>1.000652e+00</td>\n",
       "      <td>1.000652e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.141852e+00</td>\n",
       "      <td>-3.783654e+00</td>\n",
       "      <td>-3.572597e+00</td>\n",
       "      <td>-1.288212e+00</td>\n",
       "      <td>-6.928906e-01</td>\n",
       "      <td>-4.060474e+00</td>\n",
       "      <td>-1.189553e+00</td>\n",
       "      <td>-1.041549e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.448851e-01</td>\n",
       "      <td>-6.852363e-01</td>\n",
       "      <td>-3.673367e-01</td>\n",
       "      <td>-1.288212e+00</td>\n",
       "      <td>-6.928906e-01</td>\n",
       "      <td>-5.955785e-01</td>\n",
       "      <td>-6.889685e-01</td>\n",
       "      <td>-7.862862e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.509521e-01</td>\n",
       "      <td>-1.218877e-01</td>\n",
       "      <td>1.496408e-01</td>\n",
       "      <td>1.545332e-01</td>\n",
       "      <td>-4.280622e-01</td>\n",
       "      <td>9.419788e-04</td>\n",
       "      <td>-3.001282e-01</td>\n",
       "      <td>-3.608474e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.399473e-01</td>\n",
       "      <td>6.057709e-01</td>\n",
       "      <td>5.632228e-01</td>\n",
       "      <td>7.190857e-01</td>\n",
       "      <td>4.120079e-01</td>\n",
       "      <td>5.847705e-01</td>\n",
       "      <td>4.662269e-01</td>\n",
       "      <td>6.602056e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.906578e+00</td>\n",
       "      <td>2.444478e+00</td>\n",
       "      <td>2.734528e+00</td>\n",
       "      <td>4.921866e+00</td>\n",
       "      <td>6.652839e+00</td>\n",
       "      <td>4.455807e+00</td>\n",
       "      <td>5.883565e+00</td>\n",
       "      <td>4.063716e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4  \\\n",
       "count  7.680000e+02  7.680000e+02  7.680000e+02  7.680000e+02  7.680000e+02   \n",
       "mean  -7.748432e-17  3.614007e-18 -1.327244e-17  7.762888e-17 -5.493291e-17   \n",
       "std    1.000652e+00  1.000652e+00  1.000652e+00  1.000652e+00  1.000652e+00   \n",
       "min   -1.141852e+00 -3.783654e+00 -3.572597e+00 -1.288212e+00 -6.928906e-01   \n",
       "25%   -8.448851e-01 -6.852363e-01 -3.673367e-01 -1.288212e+00 -6.928906e-01   \n",
       "50%   -2.509521e-01 -1.218877e-01  1.496408e-01  1.545332e-01 -4.280622e-01   \n",
       "75%    6.399473e-01  6.057709e-01  5.632228e-01  7.190857e-01  4.120079e-01   \n",
       "max    3.906578e+00  2.444478e+00  2.734528e+00  4.921866e+00  6.652839e+00   \n",
       "\n",
       "                  5             6             7  \n",
       "count  7.680000e+02  7.680000e+02  7.680000e+02  \n",
       "mean   2.972738e-15  1.924387e-15  2.192980e-16  \n",
       "std    1.000652e+00  1.000652e+00  1.000652e+00  \n",
       "min   -4.060474e+00 -1.189553e+00 -1.041549e+00  \n",
       "25%   -5.955785e-01 -6.889685e-01 -7.862862e-01  \n",
       "50%    9.419788e-04 -3.001282e-01 -3.608474e-01  \n",
       "75%    5.847705e-01  4.662269e-01  6.602056e-01  \n",
       "max    4.455807e+00  5.883565e+00  4.063716e+00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_standardized).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2gm0xQXF2YO"
   },
   "source": [
    "#### Tuning of Hyperparameters :- Batch Size and Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "onyQQ7NoF2YO"
   },
   "outputs": [],
   "source": [
    "# Importing the necessary packages\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "#from keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lxZu8i6mF2YO"
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    \n",
    "    adam=Adam(lr=0.01)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "AX6zKQg3F2YO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/home/sachin/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.721, total=   1.3s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.753, total=   0.9s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.766, total=   0.9s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.824, total=   0.9s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    4.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=10, score=0.791, total=   1.4s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    5.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.753, total=   3.3s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    8.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.701, total=   2.5s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   11.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.740, total=   2.7s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   13.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.797, total=   2.4s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   16.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ batch_size=10, epochs=50, score=0.765, total=   3.3s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.747, total=   5.0s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.675, total=   4.2s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.753, total=   7.7s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.758, total=   7.8s\n",
      "[CV] batch_size=10, epochs=100 .......................................\n",
      "[CV] ........... batch_size=10, epochs=100, score=0.765, total=   6.7s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.740, total=   1.1s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.708, total=   1.2s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.760, total=   1.3s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.843, total=   1.1s\n",
      "[CV] batch_size=20, epochs=10 ........................................\n",
      "[CV] ............ batch_size=20, epochs=10, score=0.765, total=   1.1s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.727, total=   1.9s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.695, total=   1.9s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.740, total=   2.0s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.810, total=   2.0s\n",
      "[CV] batch_size=20, epochs=50 ........................................\n",
      "[CV] ............ batch_size=20, epochs=50, score=0.745, total=   1.8s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.747, total=   2.5s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.688, total=   3.6s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.747, total=   2.5s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.797, total=   2.4s\n",
      "[CV] batch_size=20, epochs=100 .......................................\n",
      "[CV] ........... batch_size=20, epochs=100, score=0.784, total=   2.4s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.740, total=   0.6s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.701, total=   0.6s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.760, total=   0.6s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.837, total=   0.6s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.765, total=   0.9s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.727, total=   1.5s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.688, total=   1.4s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.773, total=   1.3s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.824, total=   1.2s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.771, total=   1.4s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV] ........... batch_size=40, epochs=100, score=0.721, total=   2.2s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV] ........... batch_size=40, epochs=100, score=0.714, total=   1.8s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV] ........... batch_size=40, epochs=100, score=0.792, total=   1.6s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV] ........... batch_size=40, epochs=100, score=0.824, total=   1.8s\n",
      "[CV] batch_size=40, epochs=100 .......................................\n",
      "[CV] ........... batch_size=40, epochs=100, score=0.778, total=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  1.6min finished\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
    "# Define the grid search parameters\n",
    "batch_size = [10,20,40]\n",
    "epochs = [10,50,100]\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grid = dict(batch_size = batch_size,epochs = epochs)\n",
    "# Build and fit the GridSearchCV\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grid,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "NARyGW8aF2YO",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.7709277629852295, using {'batch_size': 10, 'epochs': 10}\n",
      "0.7709277629852295,0.0346795180407784 with: {'batch_size': 10, 'epochs': 10}\n",
      "0.7513793468475342,0.03139865369808901 with: {'batch_size': 10, 'epochs': 50}\n",
      "0.7396401047706604,0.03269207978780964 with: {'batch_size': 10, 'epochs': 100}\n",
      "0.763127076625824,0.044722373489262036 with: {'batch_size': 20, 'epochs': 10}\n",
      "0.7435786604881287,0.03776463745392001 with: {'batch_size': 20, 'epochs': 50}\n",
      "0.7527035236358642,0.037981087236440274 with: {'batch_size': 20, 'epochs': 100}\n",
      "0.7605211853981018,0.04410019127895883 with: {'batch_size': 40, 'epochs': 10}\n",
      "0.7566165924072266,0.04577640902129574 with: {'batch_size': 40, 'epochs': 50}\n",
      "0.7657159924507141,0.04208105939335854 with: {'batch_size': 40, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrJizT7VF2YO"
   },
   "source": [
    "#### Tuning of Hyperparameters:- Learning rate and Drop out rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "f4OJcmqTF2YO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.747, total=   1.0s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.714, total=   1.5s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.760, total=   0.9s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.850, total=   1.1s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    4.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.758, total=   1.1s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    5.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.734, total=   0.9s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    6.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.714, total=   0.9s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    7.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.773, total=   0.9s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    8.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.830, total=   1.0s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    9.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.752, total=   1.0s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.675, total=   0.9s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.701, total=   0.9s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.740, total=   1.6s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.725, total=   1.3s\n",
      "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.739, total=   1.0s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.753, total=   0.9s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.714, total=   1.0s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.779, total=   1.0s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.837, total=   1.0s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.771, total=   0.9s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.747, total=   0.9s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.734, total=   1.4s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.753, total=   1.1s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.830, total=   1.1s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.758, total=   1.0s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.714, total=   1.0s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.584, total=   1.0s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.714, total=   1.2s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.654, total=   0.9s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.647, total=   1.0s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.760, total=   1.0s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.584, total=   1.2s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.786, total=   0.9s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.837, total=   0.9s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.771, total=   0.9s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.727, total=   0.9s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.656, total=   0.9s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.753, total=   0.9s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.830, total=   0.9s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.771, total=   0.9s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.682, total=   0.9s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.584, total=   1.2s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.773, total=   0.9s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.745, total=   0.9s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
      "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.647, total=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:   45.7s finished\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "# Defining the model\n",
    "\n",
    "def create_model(learning_rate,dropout_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8,input_dim = 8,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4,input_dim = 8,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = learning_rate)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 10,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "learning_rate = [0.001,0.01,0.1]\n",
    "dropout_rate = [0.0,0.1,0.2]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(learning_rate = learning_rate,dropout_rate = dropout_rate)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ZtMNrL0GF2YO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.7709192752838134, using {'dropout_rate': 0.1, 'learning_rate': 0.001}\n",
      "0.7657244801521301,0.04504691587288917 with: {'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
      "0.7604957222938538,0.039794230120860564 with: {'dropout_rate': 0.0, 'learning_rate': 0.01}\n",
      "0.7161870956420898,0.024730886210507227 with: {'dropout_rate': 0.0, 'learning_rate': 0.1}\n",
      "0.7709192752838134,0.039756324380482745 with: {'dropout_rate': 0.1, 'learning_rate': 0.001}\n",
      "0.764400315284729,0.03383779810967606 with: {'dropout_rate': 0.1, 'learning_rate': 0.01}\n",
      "0.6627281308174133,0.048534887000939615 with: {'dropout_rate': 0.1, 'learning_rate': 0.1}\n",
      "0.7475426435470581,0.08568477177951922 with: {'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
      "0.747534167766571,0.05696256765553116 with: {'dropout_rate': 0.2, 'learning_rate': 0.01}\n",
      "0.6862235784530639,0.06762728263635145 with: {'dropout_rate': 0.2, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ub5c4bpdF2YO"
   },
   "source": [
    "#### Tuning of Hyperparameters:- Activation Function and Kernel Initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "lByv17rPF2YO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] activation_function=softmax, init=uniform .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=uniform, score=0.649, total=   1.1s\n",
      "[CV] activation_function=softmax, init=uniform .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=uniform, score=0.584, total=   1.0s\n",
      "[CV] activation_function=softmax, init=uniform .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=uniform, score=0.630, total=   1.1s\n",
      "[CV] activation_function=softmax, init=uniform .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=uniform, score=0.745, total=   1.0s\n",
      "[CV] activation_function=softmax, init=uniform .......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    4.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=uniform, score=0.647, total=   1.3s\n",
      "[CV] activation_function=softmax, init=normal ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    5.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=normal, score=0.649, total=   1.0s\n",
      "[CV] activation_function=softmax, init=normal ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    6.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=normal, score=0.584, total=   1.0s\n",
      "[CV] activation_function=softmax, init=normal ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    7.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=normal, score=0.630, total=   1.0s\n",
      "[CV] activation_function=softmax, init=normal ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    8.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=normal, score=0.745, total=   1.4s\n",
      "[CV] activation_function=softmax, init=normal ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    9.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=softmax, init=normal, score=0.647, total=   1.2s\n",
      "[CV] activation_function=softmax, init=zero ..........................\n",
      "[CV]  activation_function=softmax, init=zero, score=0.649, total=   1.3s\n",
      "[CV] activation_function=softmax, init=zero ..........................\n",
      "[CV]  activation_function=softmax, init=zero, score=0.584, total=   1.2s\n",
      "[CV] activation_function=softmax, init=zero ..........................\n",
      "[CV]  activation_function=softmax, init=zero, score=0.630, total=   1.0s\n",
      "[CV] activation_function=softmax, init=zero ..........................\n",
      "[CV]  activation_function=softmax, init=zero, score=0.745, total=   1.0s\n",
      "[CV] activation_function=softmax, init=zero ..........................\n",
      "[CV]  activation_function=softmax, init=zero, score=0.647, total=   1.4s\n",
      "[CV] activation_function=relu, init=uniform ..........................\n",
      "[CV]  activation_function=relu, init=uniform, score=0.753, total=   1.0s\n",
      "[CV] activation_function=relu, init=uniform ..........................\n",
      "[CV]  activation_function=relu, init=uniform, score=0.721, total=   1.0s\n",
      "[CV] activation_function=relu, init=uniform ..........................\n",
      "[CV]  activation_function=relu, init=uniform, score=0.753, total=   1.0s\n",
      "[CV] activation_function=relu, init=uniform ..........................\n",
      "[CV]  activation_function=relu, init=uniform, score=0.850, total=   1.1s\n",
      "[CV] activation_function=relu, init=uniform ..........................\n",
      "[CV]  activation_function=relu, init=uniform, score=0.752, total=   1.1s\n",
      "[CV] activation_function=relu, init=normal ...........................\n",
      "[CV]  activation_function=relu, init=normal, score=0.747, total=   1.3s\n",
      "[CV] activation_function=relu, init=normal ...........................\n",
      "[CV]  activation_function=relu, init=normal, score=0.714, total=   1.2s\n",
      "[CV] activation_function=relu, init=normal ...........................\n",
      "[CV]  activation_function=relu, init=normal, score=0.753, total=   0.9s\n",
      "[CV] activation_function=relu, init=normal ...........................\n",
      "[CV]  activation_function=relu, init=normal, score=0.856, total=   0.9s\n",
      "[CV] activation_function=relu, init=normal ...........................\n",
      "[CV]  activation_function=relu, init=normal, score=0.758, total=   1.3s\n",
      "[CV] activation_function=relu, init=zero .............................\n",
      "[CV] . activation_function=relu, init=zero, score=0.649, total=   0.9s\n",
      "[CV] activation_function=relu, init=zero .............................\n",
      "[CV] . activation_function=relu, init=zero, score=0.584, total=   1.0s\n",
      "[CV] activation_function=relu, init=zero .............................\n",
      "[CV] . activation_function=relu, init=zero, score=0.630, total=   0.9s\n",
      "[CV] activation_function=relu, init=zero .............................\n",
      "[CV] . activation_function=relu, init=zero, score=0.745, total=   1.0s\n",
      "[CV] activation_function=relu, init=zero .............................\n",
      "[CV] . activation_function=relu, init=zero, score=0.647, total=   1.0s\n",
      "[CV] activation_function=tanh, init=uniform ..........................\n",
      "[CV]  activation_function=tanh, init=uniform, score=0.760, total=   1.0s\n",
      "[CV] activation_function=tanh, init=uniform ..........................\n",
      "[CV]  activation_function=tanh, init=uniform, score=0.721, total=   1.0s\n",
      "[CV] activation_function=tanh, init=uniform ..........................\n",
      "[CV]  activation_function=tanh, init=uniform, score=0.760, total=   1.1s\n",
      "[CV] activation_function=tanh, init=uniform ..........................\n",
      "[CV]  activation_function=tanh, init=uniform, score=0.837, total=   1.3s\n",
      "[CV] activation_function=tanh, init=uniform ..........................\n",
      "[CV]  activation_function=tanh, init=uniform, score=0.758, total=   1.2s\n",
      "[CV] activation_function=tanh, init=normal ...........................\n",
      "[CV]  activation_function=tanh, init=normal, score=0.766, total=   1.2s\n",
      "[CV] activation_function=tanh, init=normal ...........................\n",
      "[CV]  activation_function=tanh, init=normal, score=0.721, total=   1.1s\n",
      "[CV] activation_function=tanh, init=normal ...........................\n",
      "[CV]  activation_function=tanh, init=normal, score=0.760, total=   1.0s\n",
      "[CV] activation_function=tanh, init=normal ...........................\n",
      "[CV]  activation_function=tanh, init=normal, score=0.837, total=   1.0s\n",
      "[CV] activation_function=tanh, init=normal ...........................\n",
      "[CV]  activation_function=tanh, init=normal, score=0.745, total=   1.7s\n",
      "[CV] activation_function=tanh, init=zero .............................\n",
      "[CV] . activation_function=tanh, init=zero, score=0.649, total=   0.9s\n",
      "[CV] activation_function=tanh, init=zero .............................\n",
      "[CV] . activation_function=tanh, init=zero, score=0.584, total=   1.7s\n",
      "[CV] activation_function=tanh, init=zero .............................\n",
      "[CV] . activation_function=tanh, init=zero, score=0.630, total=   1.0s\n",
      "[CV] activation_function=tanh, init=zero .............................\n",
      "[CV] . activation_function=tanh, init=zero, score=0.745, total=   1.0s\n",
      "[CV] activation_function=tanh, init=zero .............................\n",
      "[CV] . activation_function=tanh, init=zero, score=0.647, total=   1.5s\n",
      "[CV] activation_function=linear, init=uniform ........................\n",
      "[CV]  activation_function=linear, init=uniform, score=0.773, total=   1.3s\n",
      "[CV] activation_function=linear, init=uniform ........................\n",
      "[CV]  activation_function=linear, init=uniform, score=0.714, total=   1.3s\n",
      "[CV] activation_function=linear, init=uniform ........................\n",
      "[CV]  activation_function=linear, init=uniform, score=0.773, total=   0.9s\n",
      "[CV] activation_function=linear, init=uniform ........................\n",
      "[CV]  activation_function=linear, init=uniform, score=0.824, total=   1.2s\n",
      "[CV] activation_function=linear, init=uniform ........................\n",
      "[CV]  activation_function=linear, init=uniform, score=0.752, total=   1.2s\n",
      "[CV] activation_function=linear, init=normal .........................\n",
      "[CV]  activation_function=linear, init=normal, score=0.773, total=   1.0s\n",
      "[CV] activation_function=linear, init=normal .........................\n",
      "[CV]  activation_function=linear, init=normal, score=0.721, total=   1.0s\n",
      "[CV] activation_function=linear, init=normal .........................\n",
      "[CV]  activation_function=linear, init=normal, score=0.753, total=   1.0s\n",
      "[CV] activation_function=linear, init=normal .........................\n",
      "[CV]  activation_function=linear, init=normal, score=0.830, total=   1.4s\n",
      "[CV] activation_function=linear, init=normal .........................\n",
      "[CV]  activation_function=linear, init=normal, score=0.745, total=   0.9s\n",
      "[CV] activation_function=linear, init=zero ...........................\n",
      "[CV]  activation_function=linear, init=zero, score=0.649, total=   1.1s\n",
      "[CV] activation_function=linear, init=zero ...........................\n",
      "[CV]  activation_function=linear, init=zero, score=0.584, total=   1.1s\n",
      "[CV] activation_function=linear, init=zero ...........................\n",
      "[CV]  activation_function=linear, init=zero, score=0.630, total=   1.1s\n",
      "[CV] activation_function=linear, init=zero ...........................\n",
      "[CV]  activation_function=linear, init=zero, score=0.745, total=   1.0s\n",
      "[CV] activation_function=linear, init=zero ...........................\n",
      "[CV]  activation_function=linear, init=zero, score=0.647, total=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "# Defining the model\n",
    "\n",
    "def create_model(activation_function,init):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8,input_dim = 8,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(4,input_dim = 8,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 10,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "activation_function = ['softmax','relu','tanh','linear']\n",
    "init = ['uniform','normal','zero']\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grids = dict(activation_function = activation_function,init = init)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "YkbCsNd8F2YO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.7670061945915222, using {'activation_function': 'tanh', 'init': 'uniform'}\n",
      "0.6511586427688598,0.05244526932680711 with: {'activation_function': 'softmax', 'init': 'uniform'}\n",
      "0.6511586427688598,0.05244526932680711 with: {'activation_function': 'softmax', 'init': 'normal'}\n",
      "0.6511586427688598,0.05244526932680711 with: {'activation_function': 'softmax', 'init': 'zero'}\n",
      "0.7657159805297852,0.043766183511499114 with: {'activation_function': 'relu', 'init': 'uniform'}\n",
      "0.7657329678535462,0.047762105361542746 with: {'activation_function': 'relu', 'init': 'normal'}\n",
      "0.6511586427688598,0.05244526932680711 with: {'activation_function': 'relu', 'init': 'zero'}\n",
      "0.7670061945915222,0.03785255603113226 with: {'activation_function': 'tanh', 'init': 'uniform'}\n",
      "0.7656905174255371,0.038743037620730746 with: {'activation_function': 'tanh', 'init': 'normal'}\n",
      "0.6511586427688598,0.05244526932680711 with: {'activation_function': 'tanh', 'init': 'zero'}\n",
      "0.7669807314872742,0.03542904052396026 with: {'activation_function': 'linear', 'init': 'uniform'}\n",
      "0.764383327960968,0.03682665836848327 with: {'activation_function': 'linear', 'init': 'normal'}\n",
      "0.6511586427688598,0.05244526932680711 with: {'activation_function': 'linear', 'init': 'zero'}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGi6n1DMF2YO"
   },
   "source": [
    "#### Tuning of Hyperparameter :-Number of Neurons in activation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "vbfgmxskF2YO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=0.760, total=   1.2s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=0.708, total=   1.0s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=0.753, total=   1.3s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=0.830, total=   0.9s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    4.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=0.752, total=   0.9s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    5.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=0.766, total=   1.3s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    6.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=0.714, total=   1.4s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    8.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=0.753, total=   0.9s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    8.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=0.837, total=   1.4s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   10.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=0.745, total=   0.9s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=8, score=0.766, total=   0.9s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=8, score=0.727, total=   0.9s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=8, score=0.753, total=   0.9s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=8, score=0.837, total=   1.2s\n",
      "[CV] neuron1=4, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=8, score=0.758, total=   1.2s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.773, total=   1.6s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.721, total=   0.9s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.753, total=   0.9s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.837, total=   1.4s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.739, total=   1.3s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=0.766, total=   0.9s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=0.727, total=   0.9s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=0.760, total=   1.2s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=0.850, total=   0.9s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=0.739, total=   0.9s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=0.773, total=   0.9s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=0.727, total=   0.9s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=0.753, total=   0.9s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=0.837, total=   0.9s\n",
      "[CV] neuron1=8, neuron2=8 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=8, score=0.778, total=   0.9s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=0.766, total=   0.9s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=0.734, total=   0.9s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=0.753, total=   0.9s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=0.843, total=   1.2s\n",
      "[CV] neuron1=16, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=2, score=0.745, total=   0.9s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=0.766, total=   0.9s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=0.734, total=   0.9s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=0.753, total=   0.9s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=0.850, total=   0.9s\n",
      "[CV] neuron1=16, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=4, score=0.752, total=   0.9s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=0.779, total=   0.9s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=0.727, total=   0.9s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=0.753, total=   1.2s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=0.843, total=   0.9s\n",
      "[CV] neuron1=16, neuron2=8 ...........................................\n",
      "[CV] ............... neuron1=16, neuron2=8, score=0.745, total=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:   45.7s finished\n"
     ]
    }
   ],
   "source": [
    "# Defining the model\n",
    "\n",
    "def create_model(neuron1,neuron2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1,input_dim = 8,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 10,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "neuron1 = [4,8,16]\n",
    "neuron2 = [2,4,8]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(neuron1 = neuron1,neuron2 = neuron2)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "7FqW7Z4lF2YO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.7735251665115357, using {'neuron1': 8, 'neuron2': 8}\n",
      "0.7604957103729248,0.03936811791263353 with: {'neuron1': 4, 'neuron2': 2}\n",
      "0.763093113899231,0.040537029002738756 with: {'neuron1': 4, 'neuron2': 4}\n",
      "0.7683048963546752,0.03655624038846817 with: {'neuron1': 4, 'neuron2': 8}\n",
      "0.764383327960968,0.0399427961974151 with: {'neuron1': 8, 'neuron2': 2}\n",
      "0.7682964086532593,0.04305047299717009 with: {'neuron1': 8, 'neuron2': 4}\n",
      "0.7735251665115357,0.03618790840176079 with: {'neuron1': 8, 'neuron2': 8}\n",
      "0.7682964086532593,0.038890606088203876 with: {'neuron1': 16, 'neuron2': 2}\n",
      "0.7709107875823975,0.04071541200913948 with: {'neuron1': 16, 'neuron2': 4}\n",
      "0.7695951104164124,0.040397176312450704 with: {'neuron1': 16, 'neuron2': 8}\n"
     ]
    }
   ],
   "source": [
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aIC5R2HLF2YO"
   },
   "source": [
    "#### Training model with optimum values of Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "CSmGm5WLF2YO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7838541666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Defining the model\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8,input_dim = 8,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(8,input_dim = 8,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001) #sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 20,epochs = 10)\n",
    "\n",
    "# Fitting the model\n",
    "\n",
    "model.fit(X_standardized,y)\n",
    "\n",
    "# Predicting using trained model\n",
    "\n",
    "y_predict = model.predict(X_standardized)\n",
    "\n",
    "# Printing the metrics\n",
    "print(accuracy_score(y,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8apqs-0jF2YO"
   },
   "source": [
    "# Hyperparameters all at once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xx1m-2nVF2YO"
   },
   "source": [
    "\n",
    "The hyperparameter optimization was carried out by taking 2 hyperparameters at once. We may have missed the best values. The performance can be further improved by finding the optimum values of hyperparameters all at once given by the code snippet below.\n",
    "#### This process is computationally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6LFxZ_KlF2YO"
   },
   "outputs": [],
   "source": [
    "def create_model(learning_rate,dropout_rate,activation_function,init,neuron1,neuron2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1,input_dim = 8,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = learning_rate)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "batch_size = [10,20,40]\n",
    "epochs = [10,50,100]\n",
    "learning_rate = [0.001,0.01,0.1]\n",
    "dropout_rate = [0.0,0.1,0.2]\n",
    "activation_function = ['softmax','relu','tanh','linear']\n",
    "init = ['uniform','normal','zero']\n",
    "neuron1 = [4,8,16]\n",
    "neuron2 = [2,4,8]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(batch_size = batch_size,epochs = epochs,learning_rate = learning_rate,dropout_rate = dropout_rate,\n",
    "                   activation_function = activation_function,init = init,neuron1 = neuron1,neuron2 = neuron2)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)\n",
    "\n",
    "# Summarize the results\n",
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgJEMz5tF2YO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2.NN_Hyperparameter Tuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
